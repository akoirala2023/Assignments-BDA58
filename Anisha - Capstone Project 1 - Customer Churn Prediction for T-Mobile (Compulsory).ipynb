{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530cb2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "data = pd.read_csv(\"Ecommerce_Customer_Behavior.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445dd145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b2757",
   "metadata": {},
   "source": [
    "# Task 1: Understanding Customer Behavior - Overview Statistics and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72497ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate summary statistics for key columns\n",
    "summary_stats = data[['Total Spend', 'Items Purchased', 'Average Rating', 'Days Since Last Purchase']].describe()\n",
    "\n",
    "#Visualization of Total Spend distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Total Spend'], kde=True)\n",
    "plt.title('Distribution of Total Spend')\n",
    "plt.xlabel('Total Spend')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "#Visualization of Items Purchased distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Items Purchased'], kde=True)\n",
    "plt.title('Distribution of Items Purchased')\n",
    "plt.xlabel('Items Purchased')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Display summary statistics to user\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Summary Statistics for Key Customer Behavior Metrics\", dataframe=summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073e217e",
   "metadata": {},
   "source": [
    "# Task 2: Data Cleaning and Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values in the dataset\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "#Handle missing values (if any) - For this demonstration, I'll drop any rows with missing values.\n",
    "data_cleaned = data.dropna()\n",
    "\n",
    "#Check for and handle outliers using the Interquartile Range (IQR) method for numerical columns\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "#Remove outliers in the numerical columns\n",
    "columns_to_clean = ['Total Spend', 'Items Purchased', 'Days Since Last Purchase']\n",
    "for col in columns_to_clean:\n",
    "    data_cleaned = remove_outliers(data_cleaned, col)\n",
    "\n",
    "#Perform EDA: Visualization of Membership Type vs Total Spend\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Membership Type', y='Total Spend', data=data_cleaned)\n",
    "plt.title('Total Spend by Membership Type')\n",
    "plt.xlabel('Membership Type')\n",
    "plt.ylabel('Total Spend')\n",
    "plt.show()\n",
    "\n",
    "#Perform EDA: Visualization of Satisfaction Level vs Days Since Last Purchase\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Satisfaction Level', y='Days Since Last Purchase', data=data_cleaned)\n",
    "plt.title('Days Since Last Purchase by Satisfaction Level')\n",
    "plt.xlabel('Satisfaction Level')\n",
    "plt.ylabel('Days Since Last Purchase')\n",
    "plt.show()\n",
    "\n",
    "#Display missing values report to user\n",
    "tools.display_dataframe_to_user(name=\"Missing Values in the Dataset\", dataframe=missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d476a",
   "metadata": {},
   "source": [
    "# Task 3: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc728ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new features to enhance the predictive model's accuracy\n",
    "\n",
    "#Feature: Average Spend per Item\n",
    "data_cleaned['Avg Spend per Item'] = data_cleaned['Total Spend'] / data_cleaned['Items Purchased']\n",
    "\n",
    "#Feature: Recency Category based on Days Since Last Purchase\n",
    "data_cleaned['Recency Category'] = pd.cut(data_cleaned['Days Since Last Purchase'],\n",
    "                                          bins=[0, 15, 30, 45, data_cleaned['Days Since Last Purchase'].max()],\n",
    "                                          labels=['Very Recent', 'Recent', 'Less Recent', 'Not Recent'])\n",
    "\n",
    "#Feature: High Spender (flag for customers who spend above the median spend)\n",
    "median_spend = data_cleaned['Total Spend'].median()\n",
    "data_cleaned['High Spender'] = data_cleaned['Total Spend'] > median_spend\n",
    "\n",
    "#Visualize newly created features\n",
    "\n",
    "#Visualization of Average Spend per Item distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data_cleaned['Avg Spend per Item'], kde=True)\n",
    "plt.title('Distribution of Average Spend per Item')\n",
    "plt.xlabel('Average Spend per Item')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "#Visualization of High Spenders by Satisfaction Level\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Satisfaction Level', hue='High Spender', data=data_cleaned)\n",
    "plt.title('High Spenders by Satisfaction Level')\n",
    "plt.xlabel('Satisfaction Level')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='High Spender')\n",
    "plt.show()\n",
    "\n",
    "#Displaying the cleaned dataset with new features to the user\n",
    "tools.display_dataframe_to_user(name=\"Enhanced Dataset with New Features\", dataframe=data_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67702e",
   "metadata": {},
   "source": [
    "# Task 4: Building and Training Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d67b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f650b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode categorical variables for model compatibility\n",
    "data_encoded = data_cleaned.copy()\n",
    "label_encoders = {}\n",
    "for column in ['Gender', 'City', 'Membership Type', 'Satisfaction Level', 'Recency Category']:\n",
    "    le = LabelEncoder()\n",
    "    data_encoded[column] = le.fit_transform(data_encoded[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "#Define the target variable and feature set\n",
    "X = data_encoded[['Age', 'Total Spend', 'Items Purchased', 'Average Rating', 'Days Since Last Purchase',\n",
    "                  'Avg Spend per Item', 'High Spender', 'Recency Category']]\n",
    "y = data_encoded['Satisfaction Level']  # Assuming Satisfaction Level as a proxy for churn indicator\n",
    "\n",
    "#Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Initialize and train the RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Model evaluation\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#Visualization of Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_mat, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoders['Satisfaction Level'].classes_, yticklabels=label_encoders['Satisfaction Level'].classes_)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n",
    "\n",
    "#Displaying classification report to the user\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
